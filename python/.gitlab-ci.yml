stages:
  - test
  - build
  - scan
  - deploy
  - performance
  - pages

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ""
  DOCKER_HOST: "unix:///var/run/docker.sock"
  
  # Infrastructure Variables (Managed via GitLab API by deploy.sh)
  # GITLAB_IP: ""
  # MASTER_IP: ""
  # WORKER1_IP: ""
  # WORKER2_IP: ""
  # SSH_PASS: ""
  
  CI_REGISTRY: "${GITLAB_IP}:5050"
  IMAGE_NAME: "${CI_REGISTRY}/root/addressbook"
  APP_PORT: "30080"
  APP_URL: "http://${MASTER_IP}:${APP_PORT}"
  
  TRIVY_NO_PROGRESS: "true"
  TRIVY_SEVERITY: "HIGH,CRITICAL"
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

cache:
  paths:
    - .cache/pip
    - venv/

unit-tests:
  stage: test
  image: python:3.9-slim
  tags: [deployment]
  before_script:
    - pip install -r requirements.txt
    - pip install pytest pytest-asyncio pytest-cov
  script:
    - export PYTHONPATH=$PYTHONPATH:.
    - pytest --cov=addrservice --cov-report=term --cov-report=xml --cov-report=html tests/
  artifacts:
    paths: [htmlcov/]
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

code-quality:
  stage: test
  image: python:3.9-slim
  tags: [deployment]
  script:
    - pip install flake8
    - echo "Analyse statique du code..."
    - flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    - flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

secret-detection:
  stage: test
  image: 
    name: trufflesecurity/trufflehog:latest
    entrypoint: [""]
  tags: [deployment]
  script:
    - trufflehog git file://. --only-verified --fail
  allow_failure: true

build-image:
  stage: build
  tags: [deployment]
  script:
    - echo "[1/3] Login au registre"
    - echo "${CI_JOB_TOKEN}" | docker login ${CI_REGISTRY} -u gitlab-ci-token --password-stdin
    - echo "[2/3] Build avec cache"
    - docker build --cache-from ${IMAGE_NAME}:latest -t ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} -t ${IMAGE_NAME}:latest .
    - echo "[3/3] Push de l'image"
    - docker push ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${IMAGE_NAME}:latest

security-scan:
  stage: scan
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  tags: [deployment]
  script:
    - echo "Scan des vulnérabilités de l'image..."
    - trivy image --insecure --severity ${TRIVY_SEVERITY} ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - echo "Scan des fichiers de configuration (IaC)..."
    - trivy config --severity HIGH,CRITICAL .
  allow_failure: true

.deploy-template:
  stage: deploy
  image: ubuntu:22.04
  tags: [deployment]
  before_script:
    - export DEBIAN_FRONTEND=noninteractive
    - apt-get update -qq && apt-get install -y openssh-client ansible sshpass
    - |
      if [ -z "$SSH_PRIVATE_KEY" ]; then
        echo "[ERREUR] La variable SSH_PRIVATE_KEY est vide."
        exit 1
      fi
      eval $(ssh-agent -s)
      mkdir -p ~/.ssh
      chmod 700 ~/.ssh
      if [ -f "$SSH_PRIVATE_KEY" ]; then
          cp "$SSH_PRIVATE_KEY" ~/.ssh/id_rsa
      else
          echo "$SSH_PRIVATE_KEY" | tr -d '\r' > ~/.ssh/id_rsa
      fi
      sed -i '$a\' ~/.ssh/id_rsa
      chmod 600 ~/.ssh/id_rsa
      ssh-add ~/.ssh/id_rsa
      echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      # DNS du pauvre : Mapping des noms logiques
      echo "${GITLAB_IP} gitlab-registry" | tee -a /etc/hosts || true
      echo "${MASTER_IP} k8s-master" | tee -a /etc/hosts || true
      cat > inventory.ini <<EOF
      [gitlab]
      ${GITLAB_IP} ansible_user=debian ansible_ssh_pass=${SSH_PASS}
      
      [k8s_master]
      ${MASTER_IP} ansible_user=debian ansible_ssh_pass=${SSH_PASS}
      
      [k8s_workers]
      ${WORKER1_IP} ansible_user=debian ansible_ssh_pass=${SSH_PASS}
      ${WORKER2_IP} ansible_user=debian ansible_ssh_pass=${SSH_PASS}

      [k8s:children]
      k8s_master
      k8s_workers
      EOF
  script:
    - |
      cat > fix_registry.yml <<'EOF'
      ---
      - name: Configure Insecure Registry (Fix 02-kubernetes.yml)
        hosts: k8s
        become: yes
        tasks:
          - name: Create certs.d directory
            file:
              path: "/etc/containerd/certs.d/{{ hostvars[groups['gitlab'][0]]['inventory_hostname'] }}:5050"
              state: directory
              mode: '0755'
          
          - name: Write hosts.toml
            copy:
              dest: "/etc/containerd/certs.d/{{ hostvars[groups['gitlab'][0]]['inventory_hostname'] }}:5050/hosts.toml"
              content: |
                server = "http://{{ hostvars[groups['gitlab'][0]]['inventory_hostname'] }}:5050"
                [host."http://{{ hostvars[groups['gitlab'][0]]['inventory_hostname'] }}:5050"]
                  capabilities = ["pull", "resolve"]
              mode: '0644'

          - name: Restart containerd
            systemd:
              name: containerd
              state: restarted
      EOF
      
      ansible-playbook -i inventory.ini fix_registry.yml

    - |
      cat > deploy-app.yml <<'EOF'
      ---
      - name: HA Deployment
        hosts: k8s_master
        become: no
        vars:
          registry_url: "{{ lookup('env', 'CI_REGISTRY') }}"
          stable_token: "{{ lookup('env', 'STABLE_REGISTRY_TOKEN') }}"
          ci_token: "{{ lookup('env', 'CI_JOB_TOKEN') }}"
          app_port: "{{ lookup('env', 'APP_PORT') | default('30080', true) }}"
          namespace: "{{ lookup('env', 'K8S_NAMESPACE') | default('production', true) }}"
        tasks:
          - name: Create Namespace
            shell: kubectl create namespace {{ namespace }} --dry-run=client -o yaml | kubectl apply -f -

          - name: Create Nginx Config
            shell: |
              cat <<EOC | kubectl apply -f -
              apiVersion: v1
              kind: ConfigMap
              metadata:
                name: nginx-config
                namespace: {{ namespace }}
              data:
                nginx.conf: |
                  events {}
                  http {
                    server {
                      listen 80;
                      location / {
                        proxy_pass http://localhost:8080;
                      }
                      location /stub_status {
                        stub_status;
                        allow 127.0.0.1;
                        deny all;
                      }
                      location /metrics {
                        proxy_pass http://localhost:9113/metrics;
                      }
                    }
                  }
              EOC

          - name: Create Registry Secret
            shell: >
              kubectl create secret docker-registry gitlab-registry
              --namespace={{ namespace }}
              --docker-server={{ registry_url }}
              --docker-username=root
              --docker-password="{{ lookup('env', 'STABLE_REGISTRY_TOKEN') | default(lookup('env', 'CI_JOB_TOKEN'), true) }}"
              --docker-email=admin@example.com
              --dry-run=client -o yaml | kubectl apply -f -

          - name: Push K8s manifest
            shell: |
              cat <<EOD | kubectl apply -f -
              apiVersion: apps/v1
              kind: Deployment
              metadata: {name: addressbook, namespace: {{ namespace }}}
              spec:
                replicas: 3
                selector: {matchLabels: {app: addressbook}}
                template:
                  metadata: {labels: {app: addressbook}}
                  spec:
                    affinity:
                      podAntiAffinity:
                        preferredDuringSchedulingIgnoredDuringExecution:
                        - weight: 100
                          podAffinityTerm:
                            labelSelector:
                              matchExpressions:
                              - key: app
                                operator: In
                                values:
                                - addressbook
                            topologyKey: kubernetes.io/hostname
                    imagePullSecrets: [{name: gitlab-registry}]
                    containers:
                    - name: addressbook
                      image: {{ registry_url }}/root/addressbook:latest
                      ports: [{containerPort: 8080}]
                      resources:
                        requests:
                          cpu: "100m"
                        limits:
                          cpu: "200m"
                      readinessProbe:
                        httpGet: {path: /addresses/, port: 8080}
                        initialDelaySeconds: 10
                        periodSeconds: 5
                    - name: nginx
                      image: nginx:alpine
                      ports: [{containerPort: 80}]
                      resources:
                        requests:
                          cpu: "20m"
                        limits:
                          cpu: "100m"
                      volumeMounts:
                        - name: nginx-config-vol
                          mountPath: /etc/nginx/nginx.conf
                          subPath: nginx.conf
                    - name: exporter
                      image: nginx/nginx-prometheus-exporter:latest
                      args: ["-nginx.scrape-uri=http://localhost:80/stub_status"]
                      ports: [{containerPort: 9113}]
                      resources:
                        requests:
                          cpu: "10m"
                        limits:
                          cpu: "50m"
                    volumes:
                      - name: nginx-config-vol
                        configMap:
                          name: nginx-config
              ---
              apiVersion: autoscaling/v2
              kind: HorizontalPodAutoscaler
              metadata:
                name: addressbook-hpa
                namespace: {{ namespace }}
              spec:
                scaleTargetRef:
                  apiVersion: apps/v1
                  kind: Deployment
                  name: addressbook
                minReplicas: 2
                maxReplicas: 10
                metrics:
                - type: Resource
                  resource:
                    name: cpu
                    target:
                      type: Utilization
                      averageUtilization: 50
              ---
              apiVersion: v1
              kind: Service
              metadata: {name: addressbook-service, namespace: {{ namespace }}}
              spec:
                selector: {app: addressbook}
                ports: [{protocol: TCP, port: 30080, targetPort: 80, nodePort: {{ app_port }} }]
                type: NodePort
              EOD

          - name: Force Rollout Restart
            shell: kubectl rollout restart deployment/addressbook -n {{ namespace }}

          - name: Wait for Deployment Rollout
            shell: kubectl rollout status deployment/addressbook -n {{ namespace }} --timeout=120s

          - name: Final Health Check
            shell: |
              for i in $(seq 1 12); do
                # Check via Nginx (port 30080/nodePort -> 80) which proxies to 8080
                # We simply check localhost:{{ app_port }} which maps to the Service
                if curl -s http://localhost:{{ app_port }}/addresses/ > /dev/null; then
                  echo "Application is UP"
                  exit 0
                fi
                echo "Wait for application... ($i/12)"
                sleep 5
              done
              exit 1
      EOF
    - ansible-playbook -i inventory.ini deploy-app.yml

deploy-stagging:
  extends: .deploy-template
  variables:
    K8S_NAMESPACE: stagging
    APP_PORT: "30081"
  environment:
    name: stagging
    url: http://${MASTER_IP}:30081
  only:
    - stagging

deploy-production:
  extends: .deploy-template
  variables:
    K8S_NAMESPACE: production
    APP_PORT: "30080"
  environment:
    name: production
    url: http://${MASTER_IP}:30080
  only:
    - production
    - tags

.load-test-template:
  stage: performance
  image:
    name: grafana/k6:latest
    entrypoint: [""]
  tags: [deployment]
  script:
    - |
      k6 run -e APP_URL="${APP_URL}" - <<'EOF'
      import http from 'k6/http';
      import { sleep } from 'k6';
      
      export const options = {
        stages: [
          { duration: '30s', target: 50 }, // Ramp up to 50 users
          { duration: '1m', target: 50 },  // Stay at 50 users
          { duration: '30s', target: 0 },  // Ramp down
        ],
      };
      
      export default function () {
        const url = `${__ENV.APP_URL}/addresses/`;
        http.get(url);
        sleep(0.1); // Aggressive requests
      }
      EOF

load-test-staging:
  extends: .load-test-template
  variables:
    APP_PORT: "30081"
    APP_URL: "http://${MASTER_IP}:30081"
  only:
    - stagging

load-test-production:
  extends: .load-test-template
  variables:
    APP_PORT: "30080"
    APP_URL: "http://${MASTER_IP}:30080"
  only:
    - production
    - tags

pages:
  stage: pages
  tags: [deployment]
  dependencies: [unit-tests]
  script:
    - mkdir -p public
    - cp -r htmlcov/* public/
  artifacts:
    paths: [public]
  only: [main, master]

  only: [main, master]
