stages:
  - build
  - scan
  - deploy
  - performance

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ""
  DOCKER_HOST: "unix:///var/run/docker.sock"
  CI_REGISTRY: "192.168.122.41:5050"
  IMAGE_NAME: "${CI_REGISTRY}/root/addressbook"
  TRIVY_NO_PROGRESS: "true"
  TRIVY_SEVERITY: "HIGH,CRITICAL"

build-image:
  stage: build
  tags:
    - deployment
  script:
    - echo "[1/3] Login au registre"
    - echo "${CI_JOB_TOKEN}" | docker login ${CI_REGISTRY} -u gitlab-ci-token --password-stdin
    - echo "[2/3] Build de l'image"
    - docker build -t ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} -t ${IMAGE_NAME}:latest .
    - echo "[3/3] Push de l'image"
    - docker push ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${IMAGE_NAME}:latest

security-scan:
  stage: scan
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  tags:
    - deployment
  script:
    - trivy image --insecure --severity ${TRIVY_SEVERITY} ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} || true
    - trivy image --insecure --format json --output trivy-report.json ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} || true
  artifacts:
    paths:
      - trivy-report.json
    expire_in: 7 days
    when: always
  allow_failure: true

deploy-with-ansible:
  stage: deploy
  image: ubuntu:22.04
  tags:
    - deployment
  before_script:
    - apt-get update -qq && apt-get install -y openssh-client ansible sshpass
    - |
      if [ -z "$SSH_PRIVATE_KEY" ]; then
        echo "[ERREUR] La variable SSH_PRIVATE_KEY est vide. Vérifiez la configuration dans GitLab."
        exit 1
      fi
      eval $(ssh-agent -s)
      if [ -f "$SSH_PRIVATE_KEY" ]; then
        echo "Utilisation de SSH_PRIVATE_KEY (type File)"
        chmod 400 "$SSH_PRIVATE_KEY"
        ssh-add "$SSH_PRIVATE_KEY"
      else
        echo "Utilisation de SSH_PRIVATE_KEY (type Variable)"
        printf '%s\n' "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
      fi
      mkdir -p ~/.ssh
      chmod 700 ~/.ssh
      echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
  script:
    - echo "[1/3] Inventaire"
    - |
      cat > inventory.ini <<EOF
      [master]
      192.168.122.42 ansible_user=debian
      [workers]
      192.168.122.43 ansible_user=debian
      192.168.122.44 ansible_user=debian
      EOF
    - echo "[2/3] Création Playbook"
    - |
      cat > deploy-app.yml <<'EOF'
      ---
      - name: Pre-pull image on all nodes
        hosts: all
        become: yes
        gather_facts: no
        tasks:
          - name: Pull image securely
            command: ctr -n k8s.io image pull --plain-http --user gitlab-ci-token:{{ lookup('env', 'CI_JOB_TOKEN') }} 192.168.122.41:5050/root/addressbook:latest

      - name: Déploiement HA
        hosts: master
        gather_facts: no
        tasks:
          - name: Secret Registre
            shell: |
              kubectl create secret docker-registry gitlab-registry \
              --docker-server=192.168.122.41:5050 \
              --docker-username=gitlab-ci-token \
              --docker-password={{ lookup('env', 'CI_JOB_TOKEN') }} \
              -n production --dry-run=client -o yaml | kubectl apply -f -

          - name: Nettoyage Deployment
            command: kubectl delete deployment addressbook -n production --ignore-not-found=true

          - name: HA Deployment
            shell: |
              cat <<EOD | kubectl apply -f -
              apiVersion: apps/v1
              kind: Deployment
              metadata:
                name: addressbook
                namespace: production
              spec:
                replicas: 3
                selector:
                  matchLabels:
                    app: addressbook
                template:
                  metadata:
                    labels: {app: addressbook}
                  spec:
                    imagePullSecrets: [{name: gitlab-registry}]
                    affinity:
                      podAntiAffinity:
                        preferredDuringSchedulingIgnoredDuringExecution:
                        - weight: 100
                          podAffinityTerm:
                            labelSelector:
                              matchExpressions:
                              - key: app
                                operator: In
                                values: [addressbook]
                            topologyKey: "kubernetes.io/hostname"
                    tolerations:
                    - key: "node-role.kubernetes.io/control-plane"
                      operator: "Exists"
                      effect: "NoSchedule"
                    containers:
                    - name: addressbook
                      image: 192.168.122.41:5050/root/addressbook:latest
                      imagePullPolicy: IfNotPresent
                      ports: [{containerPort: 8080}]
                      resources:
                        requests: {cpu: 50m, memory: 64Mi}
                        limits: {cpu: 500m, memory: 256Mi}
              ---
              apiVersion: policy/v1
              kind: PodDisruptionBudget
              metadata:
                name: addressbook-pdb
                namespace: production
              spec:
                minAvailable: 2
                selector:
                  matchLabels:
                    app: addressbook
              ---
              apiVersion: v1
              kind: Service
              metadata:
                name: addressbook-service
                namespace: production
              spec:
                selector:
                  app: addressbook
                ports:
                  - protocol: TCP
                    port: 30080
                    targetPort: 8080
                    nodePort: 30080
                type: NodePort
              EOD

          - name: Attente Ready
            shell: |
              for i in {1..20}; do
                if [ "$(kubectl get pods -n production -l app=addressbook -o jsonpath='{.items[*].status.containerStatuses[*].ready}' | grep -o true | wc -l)" -ge 2 ]; then
                  echo "Pods are ready"
                  exit 0
                fi
                echo "Waiting..."
                sleep 5
              done
              exit 1

          - name: Restart Rollout
            command: kubectl rollout restart deployment addressbook -n production
      EOF
    - echo "[3/3] Ansible Play"
    - ansible-playbook -i inventory.ini deploy-app.yml

load-test:
  stage: performance
  image:
    name: grafana/k6:latest
    entrypoint: [""]
  tags:
    - deployment
  script:
    - |
      for i in {1..15}; do
        if wget --spider -q http://192.168.122.42:30080/addresses/; then
          echo "App is reachable"
          break
        fi
        echo "Waiting for app to be reachable..."
        sleep 5
      done
    - |
      k6 run - <<'EOF'
      import http from 'k6/http';
      export const options = { vus: 10, duration: '20s' };
      export default function () {
        http.get('http://192.168.122.42:30080/addresses/');
      }
      EOF
  only:
    - main
    - master